{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handmade vanila RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref http://blog.csdn.net/liuchonge/article/details/70809288\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "######################\n",
    "# model construction #\n",
    "######################\n",
    "\n",
    "batch_size = 20\n",
    "num_step = 30\n",
    "state_size = 100\n",
    "num_class = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_step], name=\"input_placeholder\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_step], name=\"output_placeholder\")\n",
    "\n",
    "x_one_hot = tf.one_hot(x, num_class)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "\n",
    "with tf.variable_scope(\"rnn_cell\"):\n",
    "    W = tf.get_variable(\"W\", [num_class + state_size, state_size])\n",
    "    b = tf.get_variable(\"b\", [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope(\"rnn_cell\", reuse=True):\n",
    "        W = tf.get_variable(\"W\", [num_class + state_size, state_size])\n",
    "        b = tf.get_variable(\"b\", [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)\n",
    "\n",
    "rnn_outputs = []\n",
    "state = tf.zeros([batch_size, state_size])\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "\n",
    "with tf.variable_scope(\"softmax\"):\n",
    "    W = tf.get_variable(\"W\", [state_size, num_class])\n",
    "    b = tf.get_variable(\"b\", [num_class])\n",
    "\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "y_as_list = tf.unstack(y, axis=1)\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(total_loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 50 for last 50 steps is 0.3757792916893959\n",
      "Average loss at step 100 for last 50 steps is 0.11165374793112277\n",
      "Average loss at step 150 for last 50 steps is 0.03906390625983477\n",
      "Average loss at step 200 for last 50 steps is 0.018498285561800002\n",
      "Average loss at step 250 for last 50 steps is 0.010696770697832108\n",
      "Average loss at step 300 for last 50 steps is 0.006974773248657584\n",
      "Average loss at step 350 for last 50 steps is 0.0049118486884981395\n",
      "Average loss at step 400 for last 50 steps is 0.0036473437352105976\n",
      "Average loss at step 450 for last 50 steps is 0.002818048680201173\n",
      "30\n",
      "[ 0.00228096  0.99771899] 1\n",
      "[ 0.9978441   0.00215586] 0\n",
      "[ 0.00207699  0.99792308] 1\n",
      "[ 0.99796677  0.00203324] 0\n",
      "[ 0.99797505  0.002025  ] 0\n",
      "[ 0.9980616  0.0019384] 0\n",
      "[ 0.99796104  0.00203894] 0\n",
      "[ 0.00208385  0.99791616] 1\n",
      "[ 0.00205249  0.99794751] 1\n",
      "[ 0.9979673   0.00203262] 0\n",
      "[ 0.00200386  0.99799621] 1\n",
      "[ 0.00207768  0.99792236] 1\n",
      "[ 0.99801111  0.00198883] 0\n",
      "[ 0.00202809  0.99797195] 1\n",
      "[ 0.99804962  0.00195035] 0\n",
      "[ 0.00201474  0.99798524] 1\n",
      "[ 0.00205819  0.99794179] 1\n",
      "[ 0.00198477  0.99801517] 1\n",
      "[ 0.0020602   0.99793977] 1\n",
      "[ 0.99797124  0.00202876] 0\n",
      "[ 0.99797374  0.00202632] 0\n",
      "[ 0.99805367  0.0019464 ] 0\n",
      "[ 0.9979887   0.00201131] 0\n",
      "[ 0.00204066  0.99795938] 1\n",
      "[ 0.99799854  0.00200143] 0\n",
      "[ 0.00199283  0.99800724] 1\n",
      "[ 0.99800402  0.00199603] 0\n",
      "[ 0.99797302  0.00202701] 0\n",
      "[ 0.00206928  0.99793077] 1\n",
      "[ 0.0020387   0.99796128] 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEakg/x8jOLM/XCLr+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f989c4e7be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_epoch(n, batch_size, num_step, num_class, seed):\n",
    "    \"\"\"generate each bathc for one epoch\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        number of total instance\n",
    "    num_step: int\n",
    "        length of sequence\n",
    "    seed: int\n",
    "        random seed\n",
    "    \"\"\"\n",
    "    def gen_sequence(num_step, num_class):\n",
    "        \"\"\"generate a sequence pair\"\"\"\n",
    "        x = np.random.choice(num_class, size=(num_step,))\n",
    "        y = x.copy()\n",
    "        return x, y\n",
    "\n",
    "    def gen_batch(batch_size, num_step, num_class):\n",
    "        \"\"\"generate data in for one batch\"\"\"\n",
    "        batch_x = np.zeros((batch_size, num_step), dtype=np.int32)\n",
    "        batch_y = np.zeros((batch_size, num_step), dtype=np.int32)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            raw_x, raw_y = gen_sequence(num_step, num_class)\n",
    "            batch_x[i] = raw_x\n",
    "            batch_y[i] = raw_y\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    for i in range(n // batch_size):\n",
    "        yield gen_batch(batch_size, num_step, num_class)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    ###################\n",
    "    # model execution #\n",
    "    ###################\n",
    "\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    sess.run(init)\n",
    "  \n",
    "    num_instance = 10000\n",
    "    num_class = 2\n",
    "    num_epoch = 1\n",
    "    random_seed = 1337\n",
    "\n",
    "    tf.set_random_seed(random_seed)\n",
    "    training_losses = []\n",
    "    \n",
    "    for i in range(num_epoch):\n",
    "        step = 0\n",
    "        training_loss = 0\n",
    "        for batch_x, batch_y in gen_epoch(num_instance, batch_size, num_step, num_class, random_seed):\n",
    "            _, training_loss_ = sess.run([optimizer, total_loss], feed_dict={x: batch_x, y: batch_y})\n",
    "            training_loss += training_loss_\n",
    "            if step % 50 == 0 and step > 0:\n",
    "                print(\"Average loss at step {} for last 50 steps is {}\".format(step, training_loss / 50))\n",
    "                training_losses.append(training_loss / 50)\n",
    "                training_loss = 0\n",
    "            step += 1\n",
    "    \n",
    "    training_rnn_inputs, training_predictions = sess.run(\n",
    "        [rnn_inputs, predictions],\n",
    "        feed_dict={x: batch_x, y: batch_y}\n",
    "    )\n",
    "    print(len(training_rnn_inputs))\n",
    "    for i in range(len(training_predictions)):\n",
    "        print(training_predictions[i][0], batch_x[0][i])\n",
    "    plt.plot(training_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow build-in RNN (static_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "######################\n",
    "# model construction #\n",
    "######################\n",
    "\n",
    "batch_size = 20\n",
    "num_step = 30\n",
    "state_size = 100\n",
    "num_class = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_step], name=\"input_placeholder\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_step], name=\"output_placeholder\")\n",
    "\n",
    "x_one_hot = tf.one_hot(x, num_class)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "state = tf.zeros([batch_size, state_size])\n",
    "rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state=state)\n",
    "\n",
    "with tf.variable_scope(\"softmax\"):\n",
    "    W = tf.get_variable(\"W\", [state_size, num_class])\n",
    "    b = tf.get_variable(\"b\", [num_class])\n",
    "\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "y_as_list = tf.unstack(y, axis=1)\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(total_loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 50 for last 50 steps is 0.604506931900978\n",
      "Average loss at step 100 for last 50 steps is 0.23648495584726334\n",
      "Average loss at step 150 for last 50 steps is 0.09437926419079304\n",
      "Average loss at step 200 for last 50 steps is 0.044342922046780586\n",
      "Average loss at step 250 for last 50 steps is 0.024959750883281232\n",
      "Average loss at step 300 for last 50 steps is 0.01587617864832282\n",
      "Average loss at step 350 for last 50 steps is 0.011076170764863492\n",
      "Average loss at step 400 for last 50 steps is 0.008154754396528005\n",
      "Average loss at step 450 for last 50 steps is 0.006267379596829414\n",
      "Average loss at step 50 for last 50 steps is 0.004122598543763161\n",
      "Average loss at step 100 for last 50 steps is 0.0033451904077082873\n",
      "Average loss at step 150 for last 50 steps is 0.002811950780451298\n",
      "Average loss at step 200 for last 50 steps is 0.0024074929999187587\n",
      "Average loss at step 250 for last 50 steps is 0.002082293028943241\n",
      "Average loss at step 300 for last 50 steps is 0.0018104443186894058\n",
      "Average loss at step 350 for last 50 steps is 0.0015970704075880349\n",
      "Average loss at step 400 for last 50 steps is 0.0014162146905437112\n",
      "Average loss at step 450 for last 50 steps is 0.0012639906513504683\n",
      "Average loss at step 50 for last 50 steps is 0.0010452052473556251\n",
      "Average loss at step 100 for last 50 steps is 0.0009280736336950212\n",
      "Average loss at step 150 for last 50 steps is 0.0008431747951544821\n",
      "Average loss at step 200 for last 50 steps is 0.0007720047538168728\n",
      "Average loss at step 250 for last 50 steps is 0.0007085853361058981\n",
      "Average loss at step 300 for last 50 steps is 0.0006497535423841327\n",
      "Average loss at step 350 for last 50 steps is 0.0006006619660183787\n",
      "Average loss at step 400 for last 50 steps is 0.0005558045022189618\n",
      "Average loss at step 450 for last 50 steps is 0.0005153893074020744\n",
      "30\n",
      "[ 0.00122481  0.99877518] 1\n",
      "[  9.99473393e-01   5.26602031e-04] 0\n",
      "[  3.69896268e-04   9.99630094e-01] 1\n",
      "[  9.99550879e-01   4.49084211e-04] 0\n",
      "[  9.99549091e-01   4.50846419e-04] 0\n",
      "[  9.99535799e-01   4.64173179e-04] 0\n",
      "[  9.99523401e-01   4.76560381e-04] 0\n",
      "[  4.59807052e-04   9.99540210e-01] 1\n",
      "[  4.99603630e-04   9.99500394e-01] 1\n",
      "[  9.99537587e-01   4.62470634e-04] 0\n",
      "[  4.64597513e-04   9.99535441e-01] 1\n",
      "[  4.80994961e-04   9.99518991e-01] 1\n",
      "[  9.99559700e-01   4.40246629e-04] 0\n",
      "[  4.64584416e-04   9.99535441e-01] 1\n",
      "[  9.99584377e-01   4.15664894e-04] 0\n",
      "[  4.47566446e-04   9.99552429e-01] 1\n",
      "[  4.40926669e-04   9.99559104e-01] 1\n",
      "[  4.44709411e-04   9.99555290e-01] 1\n",
      "[  4.61547083e-04   9.99538422e-01] 1\n",
      "[  9.99564826e-01   4.35215712e-04] 0\n",
      "[  9.99567807e-01   4.32197616e-04] 0\n",
      "[  9.99542117e-01   4.57879709e-04] 0\n",
      "[  9.99562562e-01   4.37455717e-04] 0\n",
      "[  4.69047547e-04   9.99530911e-01] 1\n",
      "[  9.99543488e-01   4.56525391e-04] 0\n",
      "[  4.66403057e-04   9.99533653e-01] 1\n",
      "[  9.99556363e-01   4.43645607e-04] 0\n",
      "[  9.99560416e-01   4.39565454e-04] 0\n",
      "[  4.42433928e-04   9.99557555e-01] 1\n",
      "[  4.71408217e-04   9.99528646e-01] 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd6QPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c3c9d4a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_epoch(n, batch_size, num_step, num_class, seed):\n",
    "    \"\"\"generate each bathc for one epoch\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        number of total instance\n",
    "    num_step: int\n",
    "        length of sequence\n",
    "    seed: int\n",
    "        random seed\n",
    "    \"\"\"\n",
    "    def gen_sequence(num_step, num_class):\n",
    "        \"\"\"generate a sequence pair\"\"\"\n",
    "        x = np.random.choice(num_class, size=(num_step,))\n",
    "        y = x.copy()\n",
    "        return x, y\n",
    "\n",
    "    def gen_batch(batch_size, num_step, num_class):\n",
    "        \"\"\"generate data in for one batch\"\"\"\n",
    "        batch_x = np.zeros((batch_size, num_step), dtype=np.int32)\n",
    "        batch_y = np.zeros((batch_size, num_step), dtype=np.int32)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            raw_x, raw_y = gen_sequence(num_step, num_class)\n",
    "            batch_x[i] = raw_x\n",
    "            batch_y[i] = raw_y\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    for i in range(n // batch_size):\n",
    "        yield gen_batch(batch_size, num_step, num_class)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    ###################\n",
    "    # model execution #\n",
    "    ###################\n",
    "\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    sess.run(init)\n",
    "  \n",
    "    num_instance = 10000\n",
    "    num_class = 2\n",
    "    num_epoch = 3\n",
    "    random_seed = 1337\n",
    "\n",
    "    tf.set_random_seed(random_seed)\n",
    "    training_losses = []\n",
    "    \n",
    "    for i in range(num_epoch):\n",
    "        step = 0\n",
    "        training_loss = 0\n",
    "        for batch_x, batch_y in gen_epoch(num_instance, batch_size, num_step, num_class, random_seed):\n",
    "            _, training_loss_ = sess.run([optimizer, total_loss], feed_dict={x: batch_x, y: batch_y})\n",
    "            training_loss += training_loss_\n",
    "            if step % 50 == 0 and step > 0:\n",
    "                print(\"Average loss at step {} for last 50 steps is {}\".format(step, training_loss / 50))\n",
    "                training_losses.append(training_loss / 50)\n",
    "                training_loss = 0\n",
    "            step += 1\n",
    "    \n",
    "    training_rnn_inputs, training_predictions = sess.run(\n",
    "        [rnn_inputs, predictions],\n",
    "        feed_dict={x: batch_x, y: batch_y}\n",
    "    )\n",
    "    print(len(training_rnn_inputs))\n",
    "    for i in range(len(training_predictions)):\n",
    "        print(training_predictions[i][0], batch_x[0][i])\n",
    "    plt.plot(training_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow build-in RNN (dynamic_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "######################\n",
    "# model construction #\n",
    "######################\n",
    "\n",
    "batch_size = 20\n",
    "num_step = 30\n",
    "state_size = 100\n",
    "num_class = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_step], name=\"input_placeholder\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_step], name=\"output_placeholder\")\n",
    "\n",
    "x_one_hot = tf.one_hot(x, num_class)\n",
    "#rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "rnn_inputs = x_one_hot\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "state = tf.zeros([batch_size, state_size])\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=state)\n",
    "\n",
    "with tf.variable_scope(\"softmax\"):\n",
    "    W = tf.get_variable(\"W\", [state_size, num_class])\n",
    "    b = tf.get_variable(\"b\", [num_class])\n",
    "    \n",
    "    \n",
    "logits = tf.reshape(\n",
    "            tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W) + b,\n",
    "            [batch_size, num_step, num_class]\n",
    ")\n",
    "predictions = tf.nn.softmax(logits)\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 50 for last 50 steps is 0.4918683820962906\n",
      "Average loss at step 100 for last 50 steps is 0.1714616310596466\n",
      "Average loss at step 150 for last 50 steps is 0.064163436293602\n",
      "Average loss at step 200 for last 50 steps is 0.029968610368669032\n",
      "Average loss at step 250 for last 50 steps is 0.017055015563964843\n",
      "Average loss at step 300 for last 50 steps is 0.011022305637598038\n",
      "Average loss at step 350 for last 50 steps is 0.007698246324434876\n",
      "Average loss at step 400 for last 50 steps is 0.005694484626874327\n",
      "Average loss at step 450 for last 50 steps is 0.004383758525364101\n",
      "Average loss at step 50 for last 50 steps is 0.0028967480780556797\n",
      "Average loss at step 100 for last 50 steps is 0.0023519122786819936\n",
      "Average loss at step 150 for last 50 steps is 0.0019839158025570214\n",
      "Average loss at step 200 for last 50 steps is 0.0016945273987948894\n",
      "Average loss at step 250 for last 50 steps is 0.0014646573038771748\n",
      "Average loss at step 300 for last 50 steps is 0.001279563216958195\n",
      "Average loss at step 350 for last 50 steps is 0.0011248998600058258\n",
      "Average loss at step 400 for last 50 steps is 0.000998191210674122\n",
      "Average loss at step 450 for last 50 steps is 0.0008904268650803715\n",
      "Average loss at step 50 for last 50 steps is 0.0007363622426055372\n",
      "Average loss at step 100 for last 50 steps is 0.0006537607940845191\n",
      "Average loss at step 150 for last 50 steps is 0.0005953131522983313\n",
      "Average loss at step 200 for last 50 steps is 0.0005437306698877364\n",
      "Average loss at step 250 for last 50 steps is 0.0004986244032625109\n",
      "Average loss at step 300 for last 50 steps is 0.0004589985153870657\n",
      "Average loss at step 350 for last 50 steps is 0.00042305858340114356\n",
      "Average loss at step 400 for last 50 steps is 0.0003916382428724319\n",
      "Average loss at step 450 for last 50 steps is 0.0003630422550486401\n",
      "30\n",
      "[  2.07438788e-04   9.99792635e-01] 1\n",
      "[  2.07438788e-04   9.99792635e-01] 0\n",
      "[  2.07438788e-04   9.99792635e-01] 1\n",
      "[  2.07438788e-04   9.99792635e-01] 0\n",
      "[  2.07438788e-04   9.99792635e-01] 0\n",
      "[  9.99494195e-01   5.05845761e-04] 0\n",
      "[  9.99494195e-01   5.05845761e-04] 0\n",
      "[  2.07438788e-04   9.99792635e-01] 1\n",
      "[  9.99494195e-01   5.05845761e-04] 1\n",
      "[  2.07438788e-04   9.99792635e-01] 0\n",
      "[  2.07438788e-04   9.99792635e-01] 1\n",
      "[  2.07438788e-04   9.99792635e-01] 1\n",
      "[  2.07438788e-04   9.99792635e-01] 0\n",
      "[  9.99494195e-01   5.05845761e-04] 1\n",
      "[  9.99494195e-01   5.05845761e-04] 0\n",
      "[  2.07438788e-04   9.99792635e-01] 1\n",
      "[  2.07438788e-04   9.99792635e-01] 1\n",
      "[  2.07438788e-04   9.99792635e-01] 1\n",
      "[  2.07438788e-04   9.99792635e-01] 1\n",
      "[  9.99494195e-01   5.05845761e-04] 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2630263f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_epoch(n, batch_size, num_step, num_class, seed):\n",
    "    \"\"\"generate each bathc for one epoch\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        number of total instance\n",
    "    num_step: int\n",
    "        length of sequence\n",
    "    seed: int\n",
    "        random seed\n",
    "    \"\"\"\n",
    "    def gen_sequence(num_step, num_class):\n",
    "        \"\"\"generate a sequence pair\"\"\"\n",
    "        x = np.random.choice(num_class, size=(num_step,))\n",
    "        y = x.copy()\n",
    "        return x, y\n",
    "\n",
    "    def gen_batch(batch_size, num_step, num_class):\n",
    "        \"\"\"generate data in for one batch\"\"\"\n",
    "        batch_x = np.zeros((batch_size, num_step), dtype=np.int32)\n",
    "        batch_y = np.zeros((batch_size, num_step), dtype=np.int32)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            raw_x, raw_y = gen_sequence(num_step, num_class)\n",
    "            batch_x[i] = raw_x\n",
    "            batch_y[i] = raw_y\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    for i in range(n // batch_size):\n",
    "        yield gen_batch(batch_size, num_step, num_class)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    ###################\n",
    "    # model execution #\n",
    "    ###################\n",
    "\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    sess.run(init)\n",
    "  \n",
    "    num_instance = 10000\n",
    "    num_class = 2\n",
    "    num_epoch = 3\n",
    "    random_seed = 1337\n",
    "\n",
    "    tf.set_random_seed(random_seed)\n",
    "    training_losses = []\n",
    "    \n",
    "    for i in range(num_epoch):\n",
    "        step = 0\n",
    "        training_loss = 0\n",
    "        for batch_x, batch_y in gen_epoch(num_instance, batch_size, num_step, num_class, random_seed):\n",
    "            _, training_loss_ = sess.run([train_op, total_loss], feed_dict={x: batch_x, y: batch_y})\n",
    "            training_loss += training_loss_\n",
    "            if step % 50 == 0 and step > 0:\n",
    "                print(\"Average loss at step {} for last 50 steps is {}\".format(step, training_loss / 50))\n",
    "                training_losses.append(training_loss / 50)\n",
    "                training_loss = 0\n",
    "            step += 1\n",
    "    \n",
    "    training_rnn_inputs, training_predictions = sess.run(\n",
    "        [rnn_inputs, predictions],\n",
    "        feed_dict={x: batch_x, y: batch_y}\n",
    "    )\n",
    "    training_rnn_inputs = np.split(training_rnn_inputs, training_rnn_inputs.shape[1], axis=1)\n",
    "    print(len(training_rnn_inputs))\n",
    "    for i in range(len(training_predictions)):\n",
    "        print(training_predictions[i][0], batch_x[0][i])\n",
    "    plt.plot(training_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow build-in RNN (dynamic_rnn with sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "######################\n",
    "# model construction #\n",
    "######################\n",
    "\n",
    "batch_size = 20\n",
    "num_step = 30\n",
    "state_size = 100\n",
    "num_class = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_step], name=\"input_placeholder\")\n",
    "x_length = tf.placeholder(tf.int32, [batch_size], name=\"input_length_placeholder\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_step], name=\"output_placeholder\")\n",
    "\n",
    "x_one_hot = tf.one_hot(x, num_class)\n",
    "#rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "rnn_inputs = x_one_hot\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "initial_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=initial_state, sequence_length=x_length)\n",
    "\n",
    "with tf.variable_scope(\"softmax\"):\n",
    "    W = tf.get_variable(\"W\", [state_size, num_class])\n",
    "    b = tf.get_variable(\"b\", [num_class])\n",
    "    \n",
    "    \n",
    "logits = tf.reshape(\n",
    "            tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W) + b,\n",
    "            [batch_size, num_step, num_class]\n",
    ")\n",
    "predictions = tf.nn.softmax(logits)\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 50 for last 50 steps is 1.061800035238266\n",
      "Average loss at step 100 for last 50 steps is 0.8627656877040863\n",
      "Average loss at step 150 for last 50 steps is 0.7584324061870575\n",
      "Average loss at step 200 for last 50 steps is 0.70289142370224\n",
      "Average loss at step 250 for last 50 steps is 0.6574127668142319\n",
      "Average loss at step 300 for last 50 steps is 0.6245595985651016\n",
      "Average loss at step 350 for last 50 steps is 0.6023646932840347\n",
      "Average loss at step 400 for last 50 steps is 0.567315279841423\n",
      "Average loss at step 450 for last 50 steps is 0.5333059006929397\n",
      "Average loss at step 50 for last 50 steps is 0.48455221235752105\n",
      "Average loss at step 100 for last 50 steps is 0.4557198470830917\n",
      "Average loss at step 150 for last 50 steps is 0.41664962351322177\n",
      "Average loss at step 200 for last 50 steps is 0.3905253452062607\n",
      "Average loss at step 250 for last 50 steps is 0.3757267934083939\n",
      "Average loss at step 300 for last 50 steps is 0.3448909389972687\n",
      "Average loss at step 350 for last 50 steps is 0.3311167424917221\n",
      "Average loss at step 400 for last 50 steps is 0.32111877501010894\n",
      "Average loss at step 450 for last 50 steps is 0.3019815281033516\n",
      "Average loss at step 50 for last 50 steps is 0.27393435657024384\n",
      "Average loss at step 100 for last 50 steps is 0.2577360528707504\n",
      "Average loss at step 150 for last 50 steps is 0.24372424989938735\n",
      "Average loss at step 200 for last 50 steps is 0.2291378316283226\n",
      "Average loss at step 250 for last 50 steps is 0.21475552201271056\n",
      "Average loss at step 300 for last 50 steps is 0.20407791078090667\n",
      "Average loss at step 350 for last 50 steps is 0.19949386805295943\n",
      "Average loss at step 400 for last 50 steps is 0.18321921184659004\n",
      "Average loss at step 450 for last 50 steps is 0.17498906582593918\n",
      "Average loss at step 50 for last 50 steps is 0.1635878501832485\n",
      "Average loss at step 100 for last 50 steps is 0.14803516909480094\n",
      "Average loss at step 150 for last 50 steps is 0.15023891687393187\n",
      "Average loss at step 200 for last 50 steps is 0.14119376927614213\n",
      "Average loss at step 250 for last 50 steps is 0.1333013179898262\n",
      "Average loss at step 300 for last 50 steps is 0.1280307674407959\n",
      "Average loss at step 350 for last 50 steps is 0.12004235446453095\n",
      "Average loss at step 400 for last 50 steps is 0.11394403859972954\n",
      "Average loss at step 450 for last 50 steps is 0.10897564902901649\n",
      "Average loss at step 50 for last 50 steps is 0.10225516989827156\n",
      "Average loss at step 100 for last 50 steps is 0.09734152242541314\n",
      "Average loss at step 150 for last 50 steps is 0.09342402264475823\n",
      "Average loss at step 200 for last 50 steps is 0.0919456971436739\n",
      "Average loss at step 250 for last 50 steps is 0.08637291118502617\n",
      "Average loss at step 300 for last 50 steps is 0.08268180720508099\n",
      "Average loss at step 350 for last 50 steps is 0.08233853347599507\n",
      "Average loss at step 400 for last 50 steps is 0.07626747980713844\n",
      "Average loss at step 450 for last 50 steps is 0.073555763438344\n",
      "Average loss at step 50 for last 50 steps is 0.06878829896450042\n",
      "Average loss at step 100 for last 50 steps is 0.06645610928535461\n",
      "Average loss at step 150 for last 50 steps is 0.06242956109344959\n",
      "Average loss at step 200 for last 50 steps is 0.059844710528850556\n",
      "Average loss at step 250 for last 50 steps is 0.05911035388708115\n",
      "Average loss at step 300 for last 50 steps is 0.05667656704783439\n",
      "Average loss at step 350 for last 50 steps is 0.053640879839658734\n",
      "Average loss at step 400 for last 50 steps is 0.05168334573507309\n",
      "Average loss at step 450 for last 50 steps is 0.049018049463629726\n",
      "Average loss at step 50 for last 50 steps is 0.04867605112493038\n",
      "Average loss at step 100 for last 50 steps is 0.04482463099062443\n",
      "Average loss at step 150 for last 50 steps is 0.04436724729835987\n",
      "Average loss at step 200 for last 50 steps is 0.043396727666258815\n",
      "Average loss at step 250 for last 50 steps is 0.04083669312298298\n",
      "Average loss at step 300 for last 50 steps is 0.03915118187665939\n",
      "Average loss at step 350 for last 50 steps is 0.03736544623970985\n",
      "Average loss at step 400 for last 50 steps is 0.03730544175952673\n",
      "Average loss at step 450 for last 50 steps is 0.03707277905195951\n",
      "Average loss at step 50 for last 50 steps is 0.03422584656625986\n",
      "Average loss at step 100 for last 50 steps is 0.03279868025332689\n",
      "Average loss at step 150 for last 50 steps is 0.03072723254561424\n",
      "Average loss at step 200 for last 50 steps is 0.030674850530922414\n",
      "Average loss at step 250 for last 50 steps is 0.030088480450212955\n",
      "Average loss at step 300 for last 50 steps is 0.02893261417746544\n",
      "Average loss at step 350 for last 50 steps is 0.027296761088073253\n",
      "Average loss at step 400 for last 50 steps is 0.027502836249768733\n",
      "Average loss at step 450 for last 50 steps is 0.02563424501568079\n",
      "Average loss at step 50 for last 50 steps is 0.02535131707787514\n",
      "Average loss at step 100 for last 50 steps is 0.023843916319310664\n",
      "Average loss at step 150 for last 50 steps is 0.023695490881800653\n",
      "Average loss at step 200 for last 50 steps is 0.023388160578906535\n",
      "Average loss at step 250 for last 50 steps is 0.02220570657402277\n",
      "Average loss at step 300 for last 50 steps is 0.02170524723827839\n",
      "Average loss at step 350 for last 50 steps is 0.021131800077855586\n",
      "Average loss at step 400 for last 50 steps is 0.02022934887558222\n",
      "Average loss at step 450 for last 50 steps is 0.01895465686917305\n",
      "Average loss at step 50 for last 50 steps is 0.018301117550581694\n",
      "Average loss at step 100 for last 50 steps is 0.017810369115322827\n",
      "Average loss at step 150 for last 50 steps is 0.016908477544784545\n",
      "Average loss at step 200 for last 50 steps is 0.01697713842615485\n",
      "Average loss at step 250 for last 50 steps is 0.016609749402850867\n",
      "Average loss at step 300 for last 50 steps is 0.016375207025557757\n",
      "Average loss at step 350 for last 50 steps is 0.015379059929400682\n",
      "Average loss at step 400 for last 50 steps is 0.015219774842262269\n",
      "Average loss at step 450 for last 50 steps is 0.014879668038338423\n",
      "30\n",
      "[  9.82598722e-05   9.99901772e-01] 1\n",
      "[  9.82598722e-05   9.99901772e-01] 0\n",
      "[  9.82598722e-05   9.99901772e-01] 1\n",
      "[  9.82598722e-05   9.99901772e-01] 0\n",
      "[  9.82598722e-05   9.99901772e-01] 0\n",
      "[  9.99998093e-01   1.91198615e-06] 0\n",
      "[  9.99998093e-01   1.91198615e-06] 0\n",
      "[  9.82598722e-05   9.99901772e-01] 1\n",
      "[  9.99998093e-01   1.91198615e-06] 1\n",
      "[  9.82598722e-05   9.99901772e-01] 0\n",
      "[  9.82598722e-05   9.99901772e-01] 1\n",
      "[  9.82598722e-05   9.99901772e-01] 1\n",
      "[  9.82598722e-05   9.99901772e-01] 0\n",
      "[  9.99998093e-01   1.91198615e-06] 1\n",
      "[  9.99998093e-01   1.91198615e-06] 0\n",
      "[  9.82598722e-05   9.99901772e-01] 1\n",
      "[  9.82598722e-05   9.99901772e-01] 1\n",
      "[  9.82598722e-05   9.99901772e-01] 1\n",
      "[  9.82598722e-05   9.99901772e-01] 1\n",
      "[  9.99998093e-01   1.91198615e-06] 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFKRwFxFJQf8N3hOu4GLDwbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd679014e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def gen_epoch(n, batch_size, num_step, num_class, seed):\n",
    "    \"\"\"generate each bathc for one epoch\n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        number of total instance\n",
    "    batch_size: int\n",
    "        size of each batch\n",
    "    num_step: int\n",
    "        length of sequence\n",
    "    num_class: int\n",
    "        number of different word in sequence\n",
    "    seed: int\n",
    "        random seed\n",
    "    \"\"\"\n",
    "    def gen_sequence(num_step, num_class, seq_length):\n",
    "        \"\"\"generate a sequence pair\"\"\"\n",
    "        x = np.random.choice(num_class, size=(num_step,))\n",
    "        x[seq_length:] = np.zeros((num_step - seq_length,))\n",
    "        y = x.copy()\n",
    "        return x, y\n",
    "\n",
    "    def gen_batch(batch_size, num_step, num_class):\n",
    "        \"\"\"generate data in for one batch\"\"\"\n",
    "        batch_x = np.zeros((batch_size, num_step), dtype=np.int32)\n",
    "        batch_x_length = np.zeros((batch_size,), dtype=np.int32)\n",
    "        batch_y = np.zeros((batch_size, num_step), dtype=np.int32)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            batch_x_length[i] = random.randint(2, num_step - 2)\n",
    "            raw_x, raw_y = gen_sequence(num_step, num_class, batch_x_length[i])\n",
    "            batch_x[i][:] = raw_x\n",
    "            batch_y[i][:] = raw_y\n",
    "        return batch_x, batch_x_length, batch_y\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    for i in range(n // batch_size):\n",
    "        yield gen_batch(batch_size, num_step, num_class)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    ###################\n",
    "    # model execution #\n",
    "    ###################\n",
    "\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    sess.run(init)\n",
    "  \n",
    "    num_instance = 10000\n",
    "    num_class = 2\n",
    "    num_epoch = 10\n",
    "    random_seed = 1337\n",
    "\n",
    "    tf.set_random_seed(random_seed)\n",
    "    training_losses = []\n",
    "    \n",
    "    for i in range(num_epoch):\n",
    "        step = 0\n",
    "        training_loss = 0\n",
    "        for batch_x, batch_x_length, batch_y in gen_epoch(num_instance, batch_size, num_step, num_class, random_seed):          \n",
    "            _, training_loss_, training_rnn_hidden, training_rnn_final = sess.run([train_op, total_loss, rnn_outputs, final_state ], feed_dict={\n",
    "                x: batch_x,\n",
    "                x_length: batch_x_length,\n",
    "                y: batch_y\n",
    "            })\n",
    "            training_loss += training_loss_\n",
    "            if step % 50 == 0 and step > 0:\n",
    "                print(\"Average loss at step {} for last 50 steps is {}\".format(step, training_loss / 50))\n",
    "                training_losses.append(training_loss / 50)\n",
    "                training_loss = 0\n",
    "                \"\"\"\n",
    "                print(training_rnn_hidden.shape, training_rnn_final.shape)\n",
    "                print(training_rnn_hidden[0][batch_x_length[0]-1][:10])\n",
    "                print(training_rnn_hidden[0][batch_x_length[0]][:10])\n",
    "                print(training_rnn_hidden[0][batch_x_length[0]+1][:10])\n",
    "                print(training_rnn_hidden[0][-1][:10])\n",
    "                print(training_rnn_final[0][:10])\n",
    "                \"\"\"\n",
    "            step += 1\n",
    "    \n",
    "    training_rnn_inputs, training_predictions = sess.run(\n",
    "        [rnn_inputs, predictions],\n",
    "        feed_dict={x: batch_x, x_length:batch_x_length, y: batch_y}\n",
    "    )\n",
    "    training_rnn_inputs = np.split(training_rnn_inputs, training_rnn_inputs.shape[1], axis=1)\n",
    "    print(len(training_rnn_inputs))\n",
    "    for i in range(len(training_predictions)):\n",
    "        print(training_predictions[i][0], batch_x[0][i])\n",
    "    plt.plot(training_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
